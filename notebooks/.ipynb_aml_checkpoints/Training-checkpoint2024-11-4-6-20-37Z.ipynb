{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from azureml.core import Workspace\n",
        "from datetime import datetime"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733208629639
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreparation:\n",
        "    \"\"\"\n",
        "    Class for preparing data. Includes loading, cleaning, and splitting.\n",
        "    This is part of the Data Preparation stage of the ML lifecycle.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load the dataset from the specified path.\"\"\"\n",
        "        df = pd.read_csv(self.data_path)\n",
        "        print(f\"Data loaded successfully from {self.data_path}\")\n",
        "        return df\n",
        "\n",
        "    def preprocess_data(self, df):\n",
        "        \"\"\"Preprocess the dataset by separating features and target.\"\"\"\n",
        "        # Separate features and target\n",
        "        X = df.drop(columns=[\"Energy_Requirement\"])\n",
        "        y = df[\"Energy_Requirement\"].apply(lambda x: 1 if x == \"Yes\" else 0)\n",
        "        print(\"Data preprocessing completed.\")\n",
        "        return X, y\n",
        "\n",
        "    def split_data(self, X, y, test_size=0.2, random_state=42):\n",
        "        \"\"\"Split the dataset into training and testing sets.\"\"\"\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "        print(\"Data split into training and testing sets.\")\n",
        "        return X_train, X_test, y_train, y_test"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733208630633
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExperimentManager:\n",
        "    \"\"\"\n",
        "    Class for managing ML experiments with multiple models.\n",
        "    This is part of the Model Training and Experimentation stage of the ML lifecycle.\n",
        "    \"\"\"\n",
        "    def __init__(self, experiment_name, workspace_config):\n",
        "        self.experiment_name = experiment_name\n",
        "        # Load the Azure ML workspace\n",
        "        self.ws = Workspace.from_config(workspace_config)\n",
        "        # Set up MLflow for tracking\n",
        "        mlflow.set_tracking_uri(self.ws.get_mlflow_tracking_uri())\n",
        "        mlflow.set_experiment(self.experiment_name)\n",
        "        print(f\"Experiment '{self.experiment_name}' is set up in MLflow.\")\n",
        "\n",
        "    def train_and_log_models(self, models, X_train, y_train, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Train and log multiple models in MLflow.\n",
        "        Logs model parameters, metrics, and artifacts.\n",
        "        \"\"\"\n",
        "        for model_name, model in models.items():\n",
        "            # Dynamically name the run based on the model and current date\n",
        "            run_name = f\"{model_name}-{datetime.now().strftime('%Y-%m-%d_%H-%M')}\"\n",
        "            with mlflow.start_run(run_name=run_name):\n",
        "                print(f\"Training and logging model: {model_name}\")\n",
        "                # Log model parameters\n",
        "                mlflow.log_param(\"model_name\", model_name)\n",
        "                \n",
        "\n",
        "                # Train the model\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "                # Predict on test data\n",
        "                y_pred = model.predict(X_test)\n",
        "\n",
        "                # Evaluate the model\n",
        "                metrics = {\n",
        "                    \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "                    \"precision\": precision_score(y_test, y_pred),\n",
        "                    \"recall\": recall_score(y_test, y_pred),\n",
        "                    \"f1_score\": f1_score(y_test, y_pred)\n",
        "                }\n",
        "\n",
        "                # Log metrics\n",
        "                for metric_name, metric_value in metrics.items():\n",
        "                    mlflow.log_metric(metric_name, metric_value)\n",
        "\n",
        "                # Log the trained model\n",
        "                mlflow.sklearn.log_model(model, artifact_path=\"models\")\n",
        "\n",
        "                # Print logged metrics for debugging\n",
        "                print(f\"Model: {model_name}, Metrics: {metrics}\")\n",
        "\n",
        "        print(f\"Experiment '{self.experiment_name}' completed. Check Azure ML Studio for results.\")\n"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733208881690
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataSaver:\n",
        "    \"\"\"\n",
        "    Class for saving prediction data for future batch prediction or testing.\n",
        "    This is part of the Deployment/Inference Preparation stage of the ML lifecycle.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def save_data(X_test, save_path):\n",
        "        \"\"\"Save the test dataset for predictions.\"\"\"\n",
        "        X_test.to_csv(save_path, index=False)\n",
        "        print(f\"Prediction data saved at: {save_path}\")"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733208882920
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths and configurations\n",
        "    DATA_PATH = \"../data/energy_data/input_data/energy_data.csv\"\n",
        "    PREDICTION_FILE = \"../data/energy_data/input_data/prediction_data.csv\"\n",
        "    WORKSPACE_CONFIG = \"./config.json\"\n",
        "    EXPERIMENT_NAME = \"energy-requirement-prediction\"\n",
        "\n",
        "    # Step 1: Data Preparation\n",
        "    data_prep = DataPreparation(DATA_PATH)\n",
        "    df = data_prep.load_data()\n",
        "    X, y = data_prep.preprocess_data(df)\n",
        "    X_train, X_test, y_train, y_test = data_prep.split_data(X, y)\n",
        "\n",
        "    # Step 2: Save prediction data\n",
        "    DataSaver.save_data(X_test, PREDICTION_FILE)\n",
        "\n",
        "    # Step 3: Experimentation\n",
        "    models = {\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=44),\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=200, random_state=44),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(random_state=44),\n",
        "        \"Support Vector Machine\": SVC(probability=True, random_state=44)\n",
        "    }\n",
        "\n",
        "    experiment_manager = ExperimentManager(EXPERIMENT_NAME, WORKSPACE_CONFIG)\n",
        "    experiment_manager.train_and_log_models(models, X_train, y_train, X_test, y_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data loaded successfully from ../data/energy_data/input_data/energy_data.csv\nData preprocessing completed.\nData split into training and testing sets.\nPrediction data saved at: ../data/energy_data/input_data/prediction_data.csv\nExperiment 'energy-requirement-prediction' is set up in MLflow.\nTraining and logging model: Random Forest\nModel: Random Forest, Metrics: {'accuracy': 0.95, 'precision': 0.9431818181818182, 'recall': 0.9431818181818182, 'f1_score': 0.9431818181818182}\nTraining and logging model: Logistic Regression\nModel: Logistic Regression, Metrics: {'accuracy': 0.835, 'precision': 0.8089887640449438, 'recall': 0.8181818181818182, 'f1_score': 0.8135593220338984}\nTraining and logging model: Decision Tree\nModel: Decision Tree, Metrics: {'accuracy': 0.895, 'precision': 0.8850574712643678, 'recall': 0.875, 'f1_score': 0.88}\nTraining and logging model: Support Vector Machine\nModel: Support Vector Machine, Metrics: {'accuracy': 0.92, 'precision': 0.9090909090909091, 'recall': 0.9090909090909091, 'f1_score': 0.9090909090909091}\nExperiment 'energy-requirement-prediction' completed. Check Azure ML Studio for results.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024/12/03 06:54:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n2024/12/03 06:54:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n2024/12/03 06:55:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n2024/12/03 06:55:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733208913057
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}